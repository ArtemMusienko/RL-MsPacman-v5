![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white)![OpenCV](https://img.shields.io/badge/opencv-%23white.svg?style=for-the-badge&logo=opencv&logoColor=white)![Google Colab](https://img.shields.io/badge/Google%20Colab-%23F9A825.svg?style=for-the-badge&logo=googlecolab&logoColor=white)![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white)![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black)

## RL ALE/MsPacman-v5

В этом коде реализовано **обучение с подкреплением (Reinforcement Learning, RL)**. В качестве игры и её версии был выбран такой вариант "**ALE/MsPacman-v5**". 

Для демонстрации работы такого подхода были выбраны 2 алгоритма, а именно: *стратегия случайного поиска* и *алгоритм восхождения на вершину*.

В качества конечного результата выводится *GIF-файл*, на котором отображается работа лучших весов в игре **Pac-Man**.

> Для запуска этого кода необязательно использовать **графические ускорители T4** или выше в **Google Colab**!
